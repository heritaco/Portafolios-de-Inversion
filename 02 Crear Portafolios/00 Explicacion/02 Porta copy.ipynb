{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizaci√≥n de Portafolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import os  # For interacting with the operating system (e.g., file paths)\n",
    "import yfinance as yf  # For fetching financial data from Yahoo Finance\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier  # For creating efficient frontier and optimizing portfolios\n",
    "from pypfopt import risk_models, expected_returns  # For calculating risk models (e.g., covariance matrix)\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices  # For discrete allocation of portfolio weights\n",
    "\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "from datetime import datetime  # For manipulating dates and times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stock_symbols(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_adj_close_prices(symbols):\n",
    "    adj_close_list = []\n",
    "    for symbol in symbols:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        hist = stock.history(period=\"max\")\n",
    "        \n",
    "        # Reset the index to work with 'Date'\n",
    "        hist.reset_index(inplace=True)\n",
    "        \n",
    "        # Convert 'Date' column to datetime and set it to UTC to standardize time zones\n",
    "        hist['Date'] = pd.to_datetime(hist['Date']).dt.tz_localize(None)  # Remove time zone info\n",
    "        \n",
    "        # Group by date to remove time component and get the last close price of the day\n",
    "        daily_data = hist.groupby(hist['Date'].dt.date).agg({'Close': 'last'}).rename(columns={'Close': symbol})\n",
    "        \n",
    "        adj_close_list.append(daily_data)\n",
    "    \n",
    "    return pd.concat(adj_close_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_dates(start_date, end_date):\n",
    "    # Generate a date range with Daily frequency\n",
    "    return pd.date_range(start=start_date, end=end_date, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herie\\AppData\\Local\\Temp\\ipykernel_19464\\1594069110.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "csv_file = f\"{current_date}.csv\"\n",
    "\n",
    "if not os.path.exists(csv_file):\n",
    "    stock_symbols = read_stock_symbols('ETFS&Stocks.txt')\n",
    "    # stock_symbols.insert(0, '^GSPC')  # Add S&P 500 symbol\n",
    "    \n",
    "    df = fetch_adj_close_prices(stock_symbols)\n",
    "\n",
    "    min_date = df.index.min()\n",
    "    max_date = df.index.max()\n",
    "\n",
    "    all_dates = pd.DataFrame(generate_all_dates(min_date, max_date), columns=['Date'])\n",
    "\n",
    "    # Convert 'Date' column to datetime to match the main dataframe\n",
    "    all_dates['Date'] = pd.to_datetime(all_dates['Date'])\n",
    "\n",
    "    # Merge the stock data with the full range of dates (business days)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Ensure 'Date' column is in datetime format\n",
    "\n",
    "    merged_df = all_dates.merge(df, on='Date', how='left')\n",
    "    merged_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    merged_df.to_csv(csv_file, index=True)\n",
    "\n",
    "# Read the resulting CSV file\n",
    "df = pd.read_csv(csv_file, index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[df.isnull().all()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = 100000\n",
    "days = 9\n",
    "rf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = (1 + rf) ** (252/days) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def save_to_excel(file_path, expected_return, volatility, sharpe_ratio, rf, leftover, type):\n",
    "    \n",
    "    workbook = load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    sheet[\"E1\"] = type\n",
    "    sheet[\"E2\"] = \"Days\"\n",
    "    sheet[\"E3\"] = \"Portafolio value\"\n",
    "    sheet[\"E4\"] = \"Return\"\n",
    "    sheet[\"E5\"] = \"Volatility\"\n",
    "    sheet[\"E6\"] = \"Sharpe Ratio\"\n",
    "    sheet[\"E7\"] = \"Risk-Free Rate\"\n",
    "    sheet[\"E8\"] = \"Leftover\"\n",
    "    sheet[\"F2\"] = days\n",
    "    sheet[\"F3\"] = portfolio\n",
    "    sheet[\"F4\"] = expected_return\n",
    "    sheet[\"F5\"] = volatility\n",
    "    sheet[\"F6\"] = sharpe_ratio\n",
    "    sheet[\"F7\"] = rf\n",
    "    sheet[\"F8\"] = leftover\n",
    "\n",
    "    workbook.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\expected_returns.py:56: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = prices.pct_change().dropna(how=\"all\")\n",
      "c:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\expected_returns.py:56: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = prices.pct_change().dropna(how=\"all\")\n",
      "c:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mu = expected_returns.mean_historical_return(df, frequency=days)\n",
    "s = risk_models.sample_cov(df, frequency=days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EfficientFrontier class is used to create an efficient frontier, which is a set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(mu, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this later for the Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"Max Return\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line optimizes the portfolio to maximize the Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ef.max_quadratic_utility()\n",
    "\n",
    "# weights = ef.max_sharpe(risk_free_rate=rf)\n",
    "# weights = ef.efficient_risk(target_volatility)\n",
    "# weights = ef.efficient_return(target_return)\n",
    "# weights = ef.min_volatility()\n",
    "# weights = ef.max_quadratic_utility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line cleans the optimized weights by rounding them and setting small weights to zero.\n",
    "The result is a more interpretable and practical set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weights = ef.clean_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line calculates the expected return, volatility, and Sharpe ratio of the optimized portfolio and assigns these values to the variables expected_return, volatility, and sharpe_ratio, respectively. The verbose=True parameter ensures that these metrics are also printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_return, volatility, sharpe_ratio = ef.portfolio_performance(verbose=True, risk_free_rate=rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet retrieves the latest prices of the assets, initializes a DiscreteAllocation object with the cleaned weights and total portfolio value, and then performs the discrete allocation to determine the number of shares to buy for each asset and the leftover cash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_prices = get_latest_prices(df)\n",
    "da = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=portfolio)\n",
    "allocation, leftover = da.lp_portfolio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet creates a list of the number of shares allocated to each company and then constructs a pandas DataFrame with two columns: 'Company Ticker' and 'Discrete Allocation'. The DataFrame provides a clear and organized view of the portfolio's allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company names for the allocation\n",
    "discrete_allocation_list = [allocation[symbol] for symbol in allocation]\n",
    "\n",
    "# Create a DataFrame for the portfolio\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Company Ticker': allocation.keys(),\n",
    "    'Discrete Allocation': discrete_allocation_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "file_path = f\"Portafolios/{type} {current_date}.xlsx\"\n",
    "portfolio_df.to_excel(file_path, index=False)\n",
    "\n",
    "save_to_excel(file_path, expected_return, volatility, sharpe_ratio, rf, leftover, type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
