{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptimizaciÃ³n de Portafolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import os  # For interacting with the operating system (e.g., file paths)\n",
    "import yfinance as yf  # For fetching financial data from Yahoo Finance\n",
    "\n",
    "# PyPortfolioOpt library for portfolio optimization\n",
    "from pypfopt.efficient_frontier import EfficientFrontier  # For creating efficient frontier and optimizing portfolios\n",
    "from pypfopt import risk_models  # For calculating risk models (e.g., covariance matrix)\n",
    "from pypfopt import expected_returns  # For calculating expected returns\n",
    "\n",
    "# PyPortfolioOpt library for discrete allocation\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices  # For discrete allocation of portfolio weights\n",
    "\n",
    "from bs4 import BeautifulSoup  # For parsing HTML and XML documents\n",
    "import pandas as pd  # Duplicate import, already imported above\n",
    "\n",
    "from datetime import datetime  # For manipulating dates and times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stock_symbols(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_adj_close_prices(symbols):\n",
    "    adj_close_list = []\n",
    "    for symbol in symbols:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        hist = stock.history(period=\"max\")\n",
    "        \n",
    "        # Reset the index to work with 'Date'\n",
    "        hist.reset_index(inplace=True)\n",
    "        \n",
    "        # Convert 'Date' column to datetime and set it to UTC to standardize time zones\n",
    "        hist['Date'] = pd.to_datetime(hist['Date']).dt.tz_localize(None)  # Remove time zone info\n",
    "        \n",
    "        # Group by date to remove time component and get the last close price of the day\n",
    "        daily_data = hist.groupby(hist['Date'].dt.date).agg({'Close': 'last'}).rename(columns={'Close': symbol})\n",
    "        \n",
    "        adj_close_list.append(daily_data)\n",
    "    \n",
    "    return pd.concat(adj_close_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_dates(start_date, end_date):\n",
    "    # Generate a date range with Daily frequency\n",
    "    return pd.date_range(start=start_date, end=end_date, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "csv_file = f\"{current_date}.csv\"\n",
    "\n",
    "if not os.path.exists(csv_file):\n",
    "    stock_symbols = read_stock_symbols('a.txt')\n",
    "    # stock_symbols.insert(0, '^GSPC')  # Add S&P 500 symbol\n",
    "    \n",
    "    df = fetch_adj_close_prices(stock_symbols)\n",
    "\n",
    "    min_date = df.index.min()\n",
    "    max_date = df.index.max()\n",
    "\n",
    "    all_dates = pd.DataFrame(generate_all_dates(min_date, max_date), columns=['Date'])\n",
    "\n",
    "    # Convert 'Date' column to datetime to match the main dataframe\n",
    "    all_dates['Date'] = pd.to_datetime(all_dates['Date'])\n",
    "\n",
    "    # Merge the stock data with the full range of dates (business days)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Ensure 'Date' column is in datetime format\n",
    "\n",
    "    merged_df = all_dates.merge(df, on='Date', how='left')\n",
    "    merged_df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    merged_df.to_csv(csv_file, index=True)\n",
    "\n",
    "# Read the resulting CSV file\n",
    "df = pd.read_csv(csv_file, index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[df.isnull().all()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove etfs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the column names from ETFS.txt\n",
    "# with open('ETFS.txt', 'r') as file:\n",
    "#     columns_to_drop = [line.strip() for line in file]\n",
    "\n",
    "# df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Portafolios\"):\n",
    "    os.makedirs(\"Portafolios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = 1000000\n",
    "days = 5\n",
    "rf = -.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mxntodlls = .05\n",
    "portfolio = portfolio * mxntodlls\n",
    "rf = (1 + rf) ** (252/days) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def save_to_excel(file_path, expected_return, volatility, sharpe_ratio, rf, leftover, type):\n",
    "    \n",
    "    workbook = load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    sheet[\"E1\"] = type\n",
    "    sheet[\"E2\"] = \"Days\"\n",
    "    sheet[\"E3\"] = \"Portafolio value\"\n",
    "    sheet[\"E4\"] = \"Return\"\n",
    "    sheet[\"E5\"] = \"Volatility\"\n",
    "    sheet[\"E6\"] = \"Sharpe Ratio\"\n",
    "    sheet[\"E7\"] = \"Risk-Free Rate\"\n",
    "    sheet[\"E8\"] = \"Leftover\"\n",
    "    sheet[\"F2\"] = days\n",
    "    sheet[\"F3\"] = portfolio\n",
    "    sheet[\"F4\"] = expected_return\n",
    "    sheet[\"F5\"] = volatility\n",
    "    sheet[\"F6\"] = sharpe_ratio\n",
    "    sheet[\"F7\"] = rf\n",
    "    sheet[\"F8\"] = leftover\n",
    "\n",
    "    workbook.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\expected_returns.py:56: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = prices.pct_change().dropna(how=\"all\")\n",
      "c:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\expected_returns.py:56: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  returns = prices.pct_change().dropna(how=\"all\")\n"
     ]
    }
   ],
   "source": [
    "mu = expected_returns.mean_historical_return(df, frequency=days)\n",
    "s = risk_models.sample_cov(df, frequency=days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EfficientFrontier class is used to create an efficient frontier, which is a set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef = EfficientFrontier(mu, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this later for the Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"Max Return\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line optimizes the portfolio to maximize the Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one of the assets must have an expected return exceeding the risk-free rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_sharpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# weights = ef.max_sharpe(risk_free_rate=rf)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# weights = ef.efficient_risk(target_volatility)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# weights = ef.efficient_return(target_return)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# weights = ef.min_volatility()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# weights = ef.max_quadratic_utility()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\herie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypfopt\\efficient_frontier\\efficient_frontier.py:245\u001b[0m, in \u001b[0;36mEfficientFrontier.max_sharpe\u001b[1;34m(self, risk_free_rate)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_free_rate should be numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_returns) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m risk_free_rate:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat least one of the assets must have an expected return exceeding the risk-free rate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_risk_free_rate \u001b[38;5;241m=\u001b[39m risk_free_rate\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# max_sharpe requires us to make a variable transformation.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Here we treat w as the transformed variable.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one of the assets must have an expected return exceeding the risk-free rate"
     ]
    }
   ],
   "source": [
    "weights = ef.max_sharpe()\n",
    "\n",
    "# weights = ef.max_sharpe(risk_free_rate=rf)\n",
    "# weights = ef.efficient_risk(target_volatility)\n",
    "# weights = ef.efficient_return(target_return)\n",
    "# weights = ef.min_volatility()\n",
    "# weights = ef.max_quadratic_utility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line cleans the optimized weights by rounding them and setting small weights to zero.\n",
    "The result is a more interpretable and practical set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_weights = ef.clean_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line calculates the expected return, volatility, and Sharpe ratio of the optimized portfolio and assigns these values to the variables expected_return, volatility, and sharpe_ratio, respectively. The verbose=True parameter ensures that these metrics are also printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: 0.2%\n",
      "Annual volatility: 5.6%\n",
      "Sharpe Ratio: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Assuming ef is an instance of EfficientFrontier and rf is defined\n",
    "expected_return, volatility, sharpe_ratio = ef.portfolio_performance(verbose=True, risk_free_rate=rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet retrieves the latest prices of the assets, initializes a DiscreteAllocation object with the cleaned weights and total portfolio value, and then performs the discrete allocation to determine the number of shares to buy for each asset and the leftover cash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_prices = get_latest_prices(df)\n",
    "da = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=portfolio)\n",
    "allocation, leftover = da.lp_portfolio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet creates a list of the number of shares allocated to each company and then constructs a pandas DataFrame with two columns: 'Company Ticker' and 'Discrete Allocation'. The DataFrame provides a clear and organized view of the portfolio's allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get company names for the allocation\n",
    "discrete_allocation_list = [allocation[symbol] for symbol in allocation]\n",
    "\n",
    "# Create a DataFrame for the portfolio\n",
    "portfolio_df = pd.DataFrame({\n",
    "    'Company Ticker': allocation.keys(),\n",
    "    'Discrete Allocation': discrete_allocation_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "file_path = f\"Portafolios/{type} {current_date}.xlsx\"\n",
    "portfolio_df.to_excel(file_path, index=False)\n",
    "\n",
    "save_to_excel(file_path, expected_return, volatility, sharpe_ratio, rf, leftover, type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
